{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1. What is Bayes' Theorem?**\n",
        "\n",
        "Bayes' Theorem describes the probability of an event based on prior knowledge of related conditions. It is mathematically expressed as:\n",
        "\n",
        "### **Example:**\n",
        "If a medical test for a disease is 90% accurate and 1% of the population has the disease, Bayes’ theorem helps determine the probability that a person actually has the disease given they tested positive.\n",
        "\n",
        "Bayes' Theorem is widely used in **Naive Bayes classifiers, spam filtering, and medical diagnosis**.\n"
      ],
      "metadata": {
        "id": "4ohpb6uoGZr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q2. What is the formula for Bayes' Theorem?**\n",
        "\n",
        "The formula for Bayes' Theorem is:\n",
        "\n",
        "\\[\n",
        "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
        "\\]\n",
        "\n",
        "### **Where:**\n",
        "- \\( P(A|B) \\) = Posterior probability (probability of A given B)\n",
        "- \\( P(B|A) \\) = Likelihood (probability of B given A)\n",
        "- \\( P(A) \\) = Prior probability (initial probability of A)\n",
        "- \\( P(B) \\) = Marginal probability of B (total probability of B occurring)\n"
      ],
      "metadata": {
        "id": "4tbVg2wRG7Tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q3. How is Bayes' Theorem used in practice?**\n",
        "\n",
        "Bayes' Theorem is widely used in various real-world applications, including:\n",
        "\n",
        "- **Spam Filtering:** Determines whether an email is spam based on word probabilities.\n",
        "- **Medical Diagnosis:** Computes the probability of a disease given test results.\n",
        "- **Fraud Detection:** Identifies fraudulent transactions based on historical data.\n",
        "- **Weather Prediction:** Updates probabilities of rain based on new weather conditions.\n",
        "- **Machine Learning (Naive Bayes Classifier):** Used for text classification and sentiment analysis.\n",
        "\n",
        "It helps in making probabilistic inferences by updating prior knowledge with new evidence.\n"
      ],
      "metadata": {
        "id": "-LrKGFkdHI_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q4. What is the relationship between Bayes' theorem and conditional probability?**\n",
        "\n",
        "Bayes' Theorem is derived from the definition of conditional probability and provides a way to update probabilities based on new evidence.\n",
        "\n",
        "- **Conditional Probability Formula:**\n",
        "  \\[\n",
        "  P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n",
        "  \\]\n",
        "  This defines the probability of event **A** occurring given that event **B** has occurred.\n",
        "\n",
        "- **Bayes' Theorem Formula:**\n",
        "  \\[\n",
        "  P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}\n",
        "  \\]\n",
        "  This expresses conditional probability in terms of its reverse probability and prior knowledge.\n",
        "\n",
        "### **Key Relationship:**\n",
        "- Bayes' theorem **reverses conditional probability** and helps compute the probability of a cause given an observed effect.\n",
        "- It is used to update beliefs as new data becomes available.\n"
      ],
      "metadata": {
        "id": "nn-b2ve6Hfjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
        "\n",
        "The choice of Naive Bayes classifier depends on the nature of the dataset and the type of features:\n",
        "\n",
        "1. **Bernoulli Naive Bayes (BNB)**  \n",
        "   - Suitable for **binary feature data** (0s and 1s).  \n",
        "   - Commonly used for **text classification** with binary term occurrence (word present or not).  \n",
        "   - Example: Spam detection (words present vs. absent in an email).\n",
        "\n",
        "2. **Multinomial Naive Bayes (MNB)**  \n",
        "   - Best for **discrete feature data**, especially **word frequency** counts.  \n",
        "   - Commonly used in **text classification** tasks (e.g., document categorization, sentiment analysis).  \n",
        "   - Example: Classifying news articles based on word occurrences.\n",
        "\n",
        "3. **Gaussian Naive Bayes (GNB)**  \n",
        "   - Used for **continuous numerical data** that follows a normal distribution.  \n",
        "   - Works well when features are real-valued, such as **sensor readings or medical data**.  \n",
        "   - Example: Classifying patients based on age, weight, and cholesterol levels.\n",
        "\n",
        "### **Choosing the Right Model:**\n",
        "- If features are **binary** → **Bernoulli NB**  \n",
        "- If features are **discrete counts** → **Multinomial NB**  \n",
        "- If features are **continuous** → **Gaussian NB**  \n",
        "- If unsure, experiment with multiple types and evaluate performance using cross-validation.\n"
      ],
      "metadata": {
        "id": "bihbG0lFHy33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q6. Assignment: Naive Bayes Classification**\n",
        "\n",
        "## You have a dataset with two features, **X1** and **X2**, and two possible classes, **A** and **B**. You want to use **Naive Bayes** to classify a new instance with features **X1 = 3** and **X2 = 4**. The following table shows the frequency of each feature value for each class:\n",
        "\n",
        "| Class | X1 = 1 | X1 = 2 | X1 = 3 | X2 = 1 | X2 = 2 | X2 = 3 | X2 = 4 |\n",
        "|-------|--------|--------|--------|--------|--------|--------|--------|\n",
        "| **A** | 3      | 3      | 4      | 4      | 3      | 3      | 3      |\n",
        "| **B** | 2      | 2      | 1      | 2      | 2      | 2      | 3      |\n",
        "\n",
        "## Assuming **equal prior probabilities** for each class, which class would **Naive Bayes** predict the new instance to belong to?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We use the **Naive Bayes classification formula**:\n",
        "\n",
        "\\[\n",
        "P(C|X) = \\frac{P(X|C) P(C)}{P(X)}\n",
        "\\]\n",
        "\n",
        "Since we assume **equal prior probabilities**, \\( P(A) = P(B) = 0.5 \\), we only need to compute the likelihood \\( P(X|C) \\).\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 1: Compute Likelihood for Class A and Class B**\n",
        "Using **relative frequency**, we estimate:\n",
        "\n",
        "\\[\n",
        "P(X1 = 3 | A) = \\frac{\\text{Count of } X1=3 \\text{ in A}}{\\text{Total count in A}} = \\frac{4}{3+3+4} = \\frac{4}{10} = 0.4\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "P(X2 = 4 | A) = \\frac{\\text{Count of } X2=4 \\text{ in A}}{\\text{Total count in A}} = \\frac{3}{4+3+3+3} = \\frac{3}{13} \\approx 0.23\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "P(X1 = 3 | B) = \\frac{\\text{Count of } X1=3 \\text{ in B}}{\\text{Total count in B}} = \\frac{1}{2+2+1} = \\frac{1}{5} = 0.2\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "P(X2 = 4 | B) = \\frac{\\text{Count of } X2=4 \\text{ in B}}{\\text{Total count in B}} = \\frac{3}{2+2+2+3} = \\frac{3}{9} = 0.33\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 2: Compute Posterior Probabilities**\n",
        "Ignoring the denominator \\( P(X) \\), we compute:\n",
        "\n",
        "\\[\n",
        "P(A|X) \\propto P(X1=3 | A) \\times P(X2=4 | A) \\times P(A)\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "P(A|X) \\propto (0.4) \\times (0.23) \\times (0.5) = 0.046\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "P(B|X) \\propto P(X1=3 | B) \\times P(X2=4 | B) \\times P(B)\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "P(B|X) \\propto (0.2) \\times (0.33) \\times (0.5) = 0.033\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 3: Classification Decision**\n",
        "Since \\( P(A|X) > P(B|X) \\), the Naive Bayes classifier predicts **Class A** for the new instance.\n",
        "\n",
        "### **Final Answer: Class A**\n"
      ],
      "metadata": {
        "id": "mEhq1G5LIJPc"
      }
    }
  ]
}